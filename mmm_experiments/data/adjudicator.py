import msgpack
import logging
from confluent_kafka import Consumer

from threading import Lock, Thread
from collections import defaultdict
from bluesky_kafka import BlueskyConsumer

logger = logging.getLogger(name="mmm.kafka")


class RecConsumer(BlueskyConsumer):
    """
    Processes reccomendations from (many) agents.

    There is no default configuration. A reasonable configuration for production is
        consumer_config={
            "auto.offset.reset": "latest"
        }

    Parameters
    ----------
    topics : list of str
        List of existing_topics as strings such as ["topic-1", "topic-2"]
    bootstrap_servers : str
        Comma-delimited list of Kafka server addresses as a string
        such as ``'broker1:9092,broker2:9092,127.0.0.1:9092'``
    group_id : str
        Required string identifier for the consumer's Kafka Consumer group.
    consumer_config : dict
        Override default configuration or specify additional configuration
        options to confluent_kafka.Consumer.
    polling_duration : float
        Time in seconds to wait for a message before running function work_during_wait
        in the _poll method. Default is 0.05.
    deserializer : function, optional
        Function to deserialize data. Default is msgpack.loads.
    process_document : function(consumer, topic, payload), optional
        A function that procceses received documents, this allows you to have custom document
        processing without the need to make a subclass. The function signature must match
        BlueskyConsumer.process_document(consumer, topic, payload).

    Example
    -------

    Print all documents generated by remote RunEngines.

    >>> consumer = BlueskyConsumer(
    >>>         topics=["abc.bluesky.documents", "xyz.bluesky.documents"],
    >>>         bootstrap_servers='localhost:9092',
    >>>         group_id="print.document.group",
    >>>         consumer_config={
    >>>             "auto.offset.reset": "latest"  # consume messages published after this consumer starts
    >>>         }
    >>>         process_document=lambda consumer, topic, name, doc: print(doc)
    >>>    )
    >>> bluesky_consumer.start(continue_polling=continue_polling)  # runs until continue_polling() returns False
    """

    def process(self, msg):
        """
        Deserialize the Kafka message and extract the bluesky document.

        Document processing is delegated to self.process_document(name, document).

        This method can be overridden to customize message handling.

        Parameters
        ----------
        msg : Kafka message

        Returns
        -------
        continue_polling : bool
            return True to continue polling, False to break out of the polling loop
        """
        print(msg.value())
        payload = self._deserializer(msg.value())
        logger.debug(
            f"{type(self)} deserialized payload with " "topic %s for Kafka Consumer name: %s doc: %s",
            msg.topic(),
            payload,
        )
        continue_polling = self.process_document(msg.topic(), payload)
        return continue_polling

    def process_document(self, topic, payload):
        """
        Subclasses may override this method to process documents.
        Alternatively a document-processing function can be specified at init time
        and it will be called here. The function must have the same signature as
        this method (except for the `self` parameter).

        If this method returns False the BlueskyConsumer will break out of the
        polling loop.

        Parameters
        ----------
        topic : str
            the Kafka topic of the message containing name and doc
        name : str
            bluesky document name: `start`, `descriptor`, `event`, etc.
        doc : dict
            bluesky document

        Returns
        -------
        continue_polling : bool
            return False to break out of the polling loop, return True to continue polling
        """
        if self._process_document is None:
            raise NotImplementedError(
                "This class must either be subclassed to override the "
                "process_document method, or have a process function passed "
                "in at init time via the process_document parameter."
            )
        else:
            continue_polling = self._process_document(self.consumer, topic, payload)
            return continue_polling


class LatestNews(RecConsumer):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._lock = Lock()
        self._by_agent = {}
        self._thread = None

    def process_document(self, topic, payload):
        with self._lock:
            # TODO by beamline level union?
            # TODO provide a beamline-first view?
            print(payload["agent"], payload["publish_uid"])
            self._by_agent[payload["agent"]] = payload
        return True

    @property
    def by_agent(self):
        with self._lock:
            # TODO worry about deepcopy
            ret = dict(self._by_agent)
        return ret

    def yeet(self):
        if self._thread is not None:
            raise RuntimeError("you can only yeet once")

        self._thread = Thread(target=self.start)
        self._thread.start()
